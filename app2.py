# =====================================
# Streamlit Web App: æ¨¡æ‹ŸProjectâ€”â€”äººäº‹ç”¨åˆåŒè®°å½•è¡¨è‡ªåŠ¨å®¡æ ¸ç³»ç»Ÿ
# ï¼ˆå››è¾“å‡ºè¡¨ + æ¼å¡«æ£€æŸ¥ + é©»åº—å®¢æˆ· + å‘é‡åŒ–ä¼˜åŒ–ç‰ˆï¼‰
# =====================================

import streamlit as st
import pandas as pd
import time
from openpyxl import Workbook, load_workbook
from openpyxl.styles import PatternFill
from io import BytesIO

# =====================================
# ğŸ åº”ç”¨æ ‡é¢˜ä¸è¯´æ˜
# =====================================
st.title("ğŸ“Š æ¨¡æ‹ŸProjectï¼šäººäº‹ç”¨åˆåŒè®°å½•è¡¨è‡ªåŠ¨å®¡æ ¸ç³»ç»Ÿï¼ˆå››Sheet + å‘é‡åŒ–ä¼˜åŒ– + æ¼å¡«æ£€æŸ¥ + é©»åº—å®¢æˆ·ï¼‰")

# =====================================
# ğŸ“‚ ä¸Šä¼ æ–‡ä»¶
# =====================================
uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ ä»¥ä¸‹æ–‡ä»¶ï¼šè®°å½•è¡¨ã€æ”¾æ¬¾æ˜ç»†ã€å­—æ®µã€äºŒæ¬¡æ˜ç»†ã€é‡å¡æ•°æ®",
    type="xlsx",
    accept_multiple_files=True
)

if not uploaded_files or len(uploaded_files) < 5:
    st.warning("âš ï¸ è¯·ä¸Šä¼ æ‰€æœ‰ 5 ä¸ªæ–‡ä»¶åç»§ç»­")
    st.stop()
else:
    st.success("âœ… æ–‡ä»¶ä¸Šä¼ å®Œæˆ")

# =====================================
# ğŸ§° å·¥å…·å‡½æ•°
# =====================================
def find_file(files_list, keyword):
    for f in files_list:
        if keyword in f.name:
            return f
    raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ã€Œ{keyword}ã€çš„æ–‡ä»¶")

def normalize_colname(c): return str(c).strip().lower()

def find_col(df, keyword, exact=False):
    key = keyword.strip().lower()
    for col in df.columns:
        cname = normalize_colname(col)
        if (exact and cname == key) or (not exact and key in cname):
            return col
    return None

def find_sheet(xls, keyword):
    for s in xls.sheet_names:
        if keyword in s:
            return s
    raise ValueError(f"âŒ æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ã€Œ{keyword}ã€çš„sheet")

def same_date_ymd(a, b):
    try:
        da = pd.to_datetime(a, errors="coerce")
        db = pd.to_datetime(b, errors="coerce")
        if pd.isna(da) or pd.isna(db): return False
        return (da.year, da.month, da.day) == (db.year, db.month, db.day)
    except Exception:
        return False

# =====================================
# ğŸ“– è¯»å–æ–‡ä»¶
# =====================================
main_file = find_file(uploaded_files, "è®°å½•è¡¨")
fk_file = find_file(uploaded_files, "æ”¾æ¬¾æ˜ç»†")
zd_file = find_file(uploaded_files, "å­—æ®µ")
ec_file = find_file(uploaded_files, "äºŒæ¬¡æ˜ç»†")
zk_file = find_file(uploaded_files, "é‡å¡æ•°æ®")

fk_xls = pd.ExcelFile(fk_file)
zd_xls = pd.ExcelFile(zd_file)

fk_df = pd.read_excel(fk_xls, sheet_name=find_sheet(fk_xls, "æœ¬å¸"))
zd_df = pd.read_excel(zd_xls, sheet_name=find_sheet(zd_xls, "é‡å¡"))
ec_df = pd.read_excel(ec_file)
zk_df = pd.read_excel(zk_file)

# è‡ªåŠ¨å»é‡åˆ—åï¼Œé¿å… merge æŠ¥é”™
for df in [fk_df, zd_df, ec_df, zk_df]:
    # è‡ªåŠ¨å»é‡åˆ—å
    def dedup_columns(columns):
        seen = {}
        new_cols = []
        for c in columns:
            if c not in seen:
                seen[c] = 0
                new_cols.append(c)
            else:
                seen[c] += 1
                new_cols.append(f"{c}.{seen[c]}")
        return new_cols

    df.columns = dedup_columns(df.columns)


# =====================================
# ğŸ§© å­—æ®µæ˜ å°„
# =====================================
mapping_fk = {"æˆä¿¡æ–¹": "æˆä¿¡", "ç§Ÿèµæœ¬é‡‘": "æœ¬é‡‘", "ç§ŸèµæœŸé™æœˆ": "ç§ŸèµæœŸé™æœˆ", "å®¢æˆ·ç»ç†": "å®¢æˆ·ç»ç†", "èµ·ç§Ÿæ”¶ç›Šç‡": "æ”¶ç›Šç‡", "ä¸»è½¦å°æ•°": "ä¸»è½¦å°æ•°", "æŒ‚è½¦å°æ•°": "æŒ‚è½¦å°æ•°"}
mapping_zd = {"ä¿è¯é‡‘æ¯”ä¾‹": "ä¿è¯é‡‘æ¯”ä¾‹_2", "é¡¹ç›®ææŠ¥äºº": "ææŠ¥", "èµ·ç§Ÿæ—¶é—´": "èµ·ç§Ÿæ—¥_å•†", "ç§ŸèµæœŸé™æœˆ": "æ€»æœŸæ•°_å•†_èµ„äº§", "æ‰€å±çœåŒº": "åŒºåŸŸ", "åŸå¸‚ç»ç†": "åŸå¸‚ç»ç†"}
mapping_ec = {"äºŒæ¬¡æ—¶é—´": "å‡ºæœ¬æµç¨‹æ—¶é—´"}
mapping_zk = {"æˆä¿¡æ–¹": "æˆä¿¡æ–¹"}

# =====================================
# âš™ï¸ å‘é‡åŒ–å¯¹æ¯”å‡½æ•°
# =====================================
def check_one_sheet_fast(sheet_keyword):
    start_time = time.time()
    xls_main = pd.ExcelFile(main_file)

    try:
        sheet_name = find_sheet(xls_main, sheet_keyword)
    except ValueError:
        st.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ…å«ã€Œ{sheet_keyword}ã€çš„sheetï¼Œè·³è¿‡ã€‚")
        return 0, 0, 0, set()

    main_df = pd.read_excel(xls_main, sheet_name=sheet_name, header=1)
    contract_col_main = find_col(main_df, "åˆåŒ")
    if not contract_col_main:
        st.error(f"âŒ åœ¨ {sheet_keyword} æœªæ‰¾åˆ°åˆåŒå·åˆ—")
        return 0, 0, 0, set()

    # è¾“å‡ºæ–‡ä»¶é¢„å¤‡
    wb = Workbook()
    ws = wb.active
    for i, c in enumerate(main_df.columns, 1): ws.cell(1, i, c)

    red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

    total_errors = 0
    skip_city_manager = 0
    contracts_seen = set(main_df[contract_col_main].dropna().astype(str).str.strip())

    # æ ¸å¿ƒå‘é‡åŒ–æ¯”å¯¹å‡½æ•°
    def batch_compare(mapping_dict, ref_df, ref_contract_col):
        nonlocal total_errors, skip_city_manager

        ref_df = ref_df.loc[:, ~ref_df.columns.duplicated()].copy()
        cols_keep = [ref_contract_col] + [v for v in mapping_dict.values() if v in ref_df.columns]
        ref_df = ref_df[cols_keep]

        merged = main_df.merge(
            ref_df,
            left_on=contract_col_main,
            right_on=ref_contract_col,
            how="left",
            suffixes=("", "_ref")
        )

        for main_kw, ref_kw in mapping_dict.items():
            if main_kw not in main_df.columns or ref_kw not in merged.columns:
                continue

            a = merged[main_kw]
            b = merged[ref_kw]

            # åŸå¸‚ç»ç†å­—æ®µè·³è¿‡ç©ºå€¼æƒ…å†µ
            if main_kw == "åŸå¸‚ç»ç†":
                skip_city_manager += b.isna().sum()
                b = b.fillna(a)  # é¿å…è¯¯åˆ¤

            # æ—¥æœŸå­—æ®µï¼šç²¾ç¡®åˆ°å¹´æœˆæ—¥
            if any(k in main_kw for k in ["æ—¥æœŸ", "æ—¶é—´"]) or any(k in ref_kw for k in ["æ—¥æœŸ", "æ—¶é—´"]):
                mismatch = ~a.combine(b, same_date_ymd)
            else:
                # å°è¯•æ•°å€¼æ¯”è¾ƒ
                a_num = pd.to_numeric(a, errors="coerce")
                b_num = pd.to_numeric(b, errors="coerce")
                both_num = a_num.notna() & b_num.notna()
                mismatch = (
                    (both_num & (abs(a_num - b_num) > 1e-6))
                    | (~both_num & (a.astype(str).str.strip() != b.astype(str).str.strip()))
                )

            total_errors += mismatch.sum()
            # æ ‡çº¢å•å…ƒæ ¼
            for idx in merged[mismatch].index:
                ws.cell(idx + 2, list(main_df.columns).index(main_kw) + 1).fill = red_fill

    # æ‰§è¡Œæ‰¹é‡å¯¹æ¯”
    contract_col_fk = find_col(fk_df, "åˆåŒ")
    contract_col_zd = find_col(zd_df, "åˆåŒ")
    contract_col_ec = find_col(ec_df, "åˆåŒ")
    contract_col_zk = find_col(zk_df, "åˆåŒ")

    batch_compare(mapping_fk, fk_df, contract_col_fk)
    batch_compare(mapping_zd, zd_df, contract_col_zd)
    batch_compare(mapping_ec, ec_df, contract_col_ec)
    batch_compare(mapping_zk, zk_df, contract_col_zk)

    # åˆåŒåˆ—é»„æ ‡
    cidx = list(main_df.columns).index(contract_col_main) + 1
    for r in range(len(main_df)):
        if any(ws.cell(r + 2, c).fill == red_fill for c in range(1, len(main_df.columns) + 1)):
            ws.cell(r + 2, cidx).fill = yellow_fill

    # å¯¼å‡º
    out = BytesIO()
    wb.save(out)
    out.seek(0)
    st.download_button(f"ğŸ“¥ ä¸‹è½½ {sheet_keyword} å®¡æ ¸ç»“æœ", out, f"è®°å½•è¡¨_{sheet_keyword}_å®¡æ ¸æ ‡æ³¨ç‰ˆ.xlsx")

    elapsed = time.time() - start_time
    st.success(f"âœ… {sheet_keyword} æ£€æŸ¥å®Œæˆï¼Œå…± {total_errors} å¤„é”™è¯¯ï¼Œç”¨æ—¶ {elapsed:.2f} ç§’ã€‚")
    return total_errors, elapsed, skip_city_manager, contracts_seen


# =====================================
# ğŸ”„ æ‰§è¡Œå››sheetæ£€æŸ¥
# =====================================
sheet_keywords = ["äºŒæ¬¡", "éƒ¨åˆ†æ‹…ä¿", "éšå·", "é©»åº—å®¢æˆ·"]
total_all = elapsed_all = skip_total = 0
contracts_seen_all_sheets = set()

for kw in sheet_keywords:
    count, used, skipped, seen = check_one_sheet_fast(kw)
    total_all += count
    elapsed_all += used
    skip_total += skipped
    contracts_seen_all_sheets.update(seen)

st.success(f"ğŸ¯ å…¨éƒ¨æ£€æŸ¥å®Œæˆï¼Œå…± {total_all} å¤„é”™è¯¯ï¼Œè€—æ—¶ {elapsed_all:.2f} ç§’ã€‚")

# =====================================
# ğŸ•µï¸ æ¼å¡«æ£€æŸ¥ï¼ˆå«è·³è¿‡æ¡ä»¶ï¼‰
# =====================================
contract_col_zd = find_col(zd_df, "åˆåŒ")
col_car_manager = find_col(zd_df, "æ˜¯å¦è½¦ç®¡å®¶", exact=True)
col_bonus_type = find_col(zd_df, "ææˆç±»å‹", exact=True)

field_contracts = zd_df[contract_col_zd].dropna().astype(str).str.strip()
missing_mask = ~field_contracts.isin(contracts_seen_all_sheets)

if col_car_manager:
    missing_mask &= ~(zd_df[col_car_manager].astype(str).str.strip() == "æ˜¯")
if col_bonus_type:
    missing_mask &= ~zd_df[col_bonus_type].astype(str).str.strip().isin(["è”åˆç§Ÿèµ", "é©»åº—"])

zd_df_missing = zd_df.copy()
zd_df_missing["æ¼å¡«æ£€æŸ¥"] = ""
zd_df_missing.loc[missing_mask, "æ¼å¡«æ£€æŸ¥"] = "â— æ¼å¡«"

æ¼å¡«æ•° = zd_df_missing["æ¼å¡«æ£€æŸ¥"].eq("â— æ¼å¡«").sum()
st.warning(f"âš ï¸ å…±å‘ç° {æ¼å¡«æ•°} ä¸ªæ¼å¡«åˆåŒï¼ˆå·²æ’é™¤è½¦ç®¡å®¶ã€è”åˆç§Ÿèµã€é©»åº—ï¼‰")

# =====================================
# ğŸ“¤ å¯¼å‡ºå­—æ®µè¡¨
# =====================================
yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

def export_excel(df, filename):
    wb = Workbook()
    ws = wb.active
    for c_idx, c in enumerate(df.columns, 1): ws.cell(1, c_idx, c)
    for r_idx, row in enumerate(df.itertuples(index=False), 2):
        for c_idx, v in enumerate(row, 1):
            ws.cell(r_idx, c_idx, v)
            if df.columns[c_idx - 1] == "æ¼å¡«æ£€æŸ¥" and v == "â— æ¼å¡«":
                ws.cell(r_idx, c_idx).fill = yellow_fill
    bio = BytesIO()
    wb.save(bio)
    bio.seek(0)
    st.download_button(f"ğŸ“¥ ä¸‹è½½ {filename}", bio, f"{filename}.xlsx")

export_excel(zd_df_missing, "å­—æ®µè¡¨_æ¼å¡«æ ‡æ³¨ç‰ˆ")
zd_df_only_missing = zd_df_missing[zd_df_missing["æ¼å¡«æ£€æŸ¥"] == "â— æ¼å¡«"]
if not zd_df_only_missing.empty:
    export_excel(zd_df_only_missing, "å­—æ®µè¡¨_ä»…æ¼å¡«")

st.success("âœ… æ‰€æœ‰æ£€æŸ¥ã€æ ‡æ³¨ä¸å¯¼å‡ºå®Œæˆï¼")

