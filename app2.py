# =====================================
# Streamlit Web App: åˆåŒè®°å½•è¡¨è‡ªåŠ¨å®¡æ ¸ï¼ˆä¼˜åŒ–ç‰ˆ - å‘é‡åŒ–æ¯”å¯¹ + å››è¾“å‡ºè¡¨ + æ¼å¡«æ£€æŸ¥ï¼‰
# =====================================

import streamlit as st
import pandas as pd
import time
from openpyxl import Workbook
from openpyxl.styles import PatternFill
from io import BytesIO

# =====================================
# ğŸ åº”ç”¨æ ‡é¢˜
# =====================================
st.title("ğŸ“Š æ¨¡æ‹ŸProjectï¼šäººäº‹ç”¨åˆåŒè®°å½•è¡¨è‡ªåŠ¨å®¡æ ¸ç³»ç»Ÿï¼ˆå››Sheet + å‘é‡åŒ–æ¯”å¯¹ + æ¼å¡«æ£€æŸ¥ä¼˜åŒ–ç‰ˆï¼‰")

# =====================================
# ğŸ“‚ ä¸Šä¼ æ–‡ä»¶åŒº
# =====================================
uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ ä»¥ä¸‹æ–‡ä»¶ï¼šè®°å½•è¡¨ã€æ”¾æ¬¾æ˜ç»†ã€å­—æ®µã€äºŒæ¬¡æ˜ç»†ã€é‡å¡æ•°æ®",
    type="xlsx",
    accept_multiple_files=True
)

if not uploaded_files or len(uploaded_files) < 5:
    st.warning("âš ï¸ è¯·ä¸Šä¼ å…¨éƒ¨ 5 ä¸ªæ–‡ä»¶åç»§ç»­")
    st.stop()
else:
    st.success("âœ… æ–‡ä»¶ä¸Šä¼ å®Œæˆ")

# =====================================
# ğŸ”§ å·¥å…·å‡½æ•°
# =====================================
def find_file(files_list, keyword):
    for f in files_list:
        if keyword in f.name:
            return f
    raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ã€Œ{keyword}ã€çš„æ–‡ä»¶")

def normalize_colname(c): return str(c).strip().lower()

def find_col(df, keyword, exact=False):
    key = keyword.strip().lower()
    for col in df.columns:
        cname = normalize_colname(col)
        if (exact and cname == key) or (not exact and key in cname):
            return col
    return None

def find_sheet(xls, keyword):
    for s in xls.sheet_names:
        if keyword in s:
            return s
    raise ValueError(f"âŒ æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ã€Œ{keyword}ã€çš„sheet")

def normalize_num(val):
    if pd.isna(val): return None
    s = str(val).replace(",", "").strip()
    if s in ["", "-", "nan"]: return None
    try:
        if "%" in s: return float(s.replace("%", "")) / 100
        return float(s)
    except ValueError:
        return s

def same_date_ymd(a, b):
    try:
        da = pd.to_datetime(a, errors='coerce')
        db = pd.to_datetime(b, errors='coerce')
        if pd.isna(da) or pd.isna(db): return False
        return (da.year, da.month, da.day) == (db.year, db.month, db.day)
    except Exception:
        return False

# =====================================
# ğŸ§® å¿«é€Ÿå¯¹ç…§å‡½æ•°ï¼ˆå‘é‡åŒ–ç‰ˆæœ¬ï¼‰
# =====================================
def check_one_sheet_fast(sheet_keyword):
    start_time = time.time()
    xls_main = pd.ExcelFile(main_file)

    try:
        target_sheet = find_sheet(xls_main, sheet_keyword)
    except ValueError:
        st.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ…å«ã€Œ{sheet_keyword}ã€çš„sheetï¼Œè·³è¿‡ã€‚")
        return 0, None, 0, set()

    main_df = pd.read_excel(xls_main, sheet_name=target_sheet, header=1)
    contract_col_main = find_col(main_df, "åˆåŒ")
    if not contract_col_main:
        st.error(f"âŒ åœ¨ã€Œ{sheet_keyword}ã€ä¸­æœªæ‰¾åˆ°åˆåŒåˆ—ã€‚")
        return 0, None, 0, set()

    main_df[contract_col_main] = main_df[contract_col_main].astype(str).str.strip()
    contracts_seen = set(main_df[contract_col_main].dropna().unique())

    red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
    wb = Workbook()
    ws = wb.active
    for c_idx, c in enumerate(main_df.columns, 1): ws.cell(1, c_idx, c)

    # === åˆå§‹åŒ–é”™è¯¯çŸ©é˜µ ===
    error_flags = pd.DataFrame(False, index=main_df.index, columns=main_df.columns)
    skip_city_manager = 0

    def batch_compare(mapping_dict, ref_df, ref_contract_col):
        nonlocal skip_city_manager
        ref_df[ref_contract_col] = ref_df[ref_contract_col].astype(str).str.strip()
        merged = main_df.merge(
            ref_df[[ref_contract_col] + list(ref_df.columns)],
            left_on=contract_col_main,
            right_on=ref_contract_col,
            how="left",
            suffixes=("", "_ref")
        )
        for main_kw, ref_kw in mapping_dict.items():
            mc = find_col(main_df, main_kw)
            rc = find_col(merged, ref_kw + "_ref") or (ref_kw + "_ref")
            if mc and rc in merged.columns:
                main_vals = merged[mc].apply(normalize_num)
                ref_vals = merged[rc].apply(normalize_num)
                mismatched = []
                for a, b in zip(main_vals, ref_vals):
                    # åŸå¸‚ç»ç†è·³è¿‡
                    if main_kw == "åŸå¸‚ç»ç†":
                        if b in [None, "", "-", "nan", "none", "null"]:
                            skip_city_manager += 1
                            mismatched.append(False)
                            continue
                    if (a is None and b is None):
                        mismatched.append(False)
                    elif any(k in main_kw for k in ["æ—¥æœŸ", "æ—¶é—´"]) or any(k in ref_kw for k in ["æ—¥æœŸ", "æ—¶é—´"]):
                        mismatched.append(not same_date_ymd(a, b))
                    elif isinstance(a, (int, float)) and isinstance(b, (int, float)):
                        diff = abs(a - b)
                        if main_kw == "ä¿è¯é‡‘æ¯”ä¾‹" and ref_kw == "ä¿è¯é‡‘æ¯”ä¾‹_2":
                            mismatched.append(diff > 0.005)
                        else:
                            mismatched.append(diff > 1e-6)
                    else:
                        mismatched.append(str(a).strip().lower().replace(".0", "") != str(b).strip().lower().replace(".0", ""))
                error_flags[mc] |= mismatched

    # === æ‰§è¡Œå››ç±»æ‰¹é‡å¯¹ç…§ ===
    batch_compare(mapping_fk, fk_df, contract_col_fk)
    batch_compare(mapping_zd, zd_df, contract_col_zd)
    batch_compare(mapping_ec, ec_df, contract_col_ec)
    batch_compare(mapping_zk, zk_df, contract_col_zk)

    # === è¾“å‡ºç»“æœ ===
    total_errors = error_flags.sum().sum()
    for i, (_, row) in enumerate(main_df.iterrows(), 2):
        row_has_error = False
        for j, col in enumerate(main_df.columns, 1):
            v = row[col]
            ws.cell(i, j, v)
            if error_flags.loc[i - 2, col]:
                ws.cell(i, j).fill = red_fill
                row_has_error = True
        if row_has_error:
            ws.cell(i, list(main_df.columns).index(contract_col_main) + 1).fill = yellow_fill

    output = BytesIO()
    wb.save(output)
    output.seek(0)
    st.download_button(f"ğŸ“¥ ä¸‹è½½ {sheet_keyword} å®¡æ ¸æ ‡æ³¨ç‰ˆ", output, f"è®°å½•è¡¨_{sheet_keyword}_å®¡æ ¸æ ‡æ³¨ç‰ˆ.xlsx")

    elapsed = time.time() - start_time
    st.success(f"âœ… {sheet_keyword} æ£€æŸ¥å®Œæˆï¼Œå…± {total_errors} å¤„é”™è¯¯ï¼Œç”¨æ—¶ {elapsed:.2f} ç§’ã€‚")
    return total_errors, elapsed, skip_city_manager, contracts_seen

# =====================================
# ğŸ“– æ–‡ä»¶è¯»å–åŒº
# =====================================
main_file = find_file(uploaded_files, "è®°å½•è¡¨")
fk_file = find_file(uploaded_files, "æ”¾æ¬¾æ˜ç»†")
zd_file = find_file(uploaded_files, "å­—æ®µ")
ec_file = find_file(uploaded_files, "äºŒæ¬¡æ˜ç»†")
zk_file = find_file(uploaded_files, "é‡å¡æ•°æ®")

fk_df = pd.read_excel(pd.ExcelFile(fk_file), sheet_name=find_sheet(pd.ExcelFile(fk_file), "æœ¬å¸"))
zd_df = pd.read_excel(pd.ExcelFile(zd_file), sheet_name=find_sheet(pd.ExcelFile(zd_file), "é‡å¡"))
ec_df = pd.read_excel(ec_file)
zk_df = pd.read_excel(zk_file)

contract_col_fk = find_col(fk_df, "åˆåŒ")
contract_col_zd = find_col(zd_df, "åˆåŒ")
contract_col_ec = find_col(ec_df, "åˆåŒ")
contract_col_zk = find_col(zk_df, "åˆåŒ")

# å­—æ®µæ˜ å°„
mapping_fk = {"æˆä¿¡æ–¹": "æˆä¿¡", "ç§Ÿèµæœ¬é‡‘": "æœ¬é‡‘", "ç§ŸèµæœŸé™æœˆ": "ç§ŸèµæœŸé™æœˆ", "å®¢æˆ·ç»ç†": "å®¢æˆ·ç»ç†", "èµ·ç§Ÿæ”¶ç›Šç‡": "æ”¶ç›Šç‡", "ä¸»è½¦å°æ•°": "ä¸»è½¦å°æ•°", "æŒ‚è½¦å°æ•°": "æŒ‚è½¦å°æ•°"}
mapping_zd = {"ä¿è¯é‡‘æ¯”ä¾‹": "ä¿è¯é‡‘æ¯”ä¾‹_2", "é¡¹ç›®ææŠ¥äºº": "ææŠ¥", "èµ·ç§Ÿæ—¶é—´": "èµ·ç§Ÿæ—¥_å•†", "ç§ŸèµæœŸé™æœˆ": "æ€»æœŸæ•°_å•†_èµ„äº§", "æ‰€å±çœåŒº": "åŒºåŸŸ", "åŸå¸‚ç»ç†": "åŸå¸‚ç»ç†"}
mapping_ec = {"äºŒæ¬¡æ—¶é—´": "å‡ºæœ¬æµç¨‹æ—¶é—´"}
mapping_zk = {"æˆä¿¡æ–¹": "æˆä¿¡æ–¹"}

# =====================================
# ğŸ§¾ å¤šsheetå¾ªç¯æ£€æŸ¥
# =====================================
sheet_keywords = ["äºŒæ¬¡", "éƒ¨åˆ†æ‹…ä¿", "éšå·", "é©»åº—å®¢æˆ·"]
total_all = elapsed_all = skip_total = 0
contracts_seen_all_sheets = set()

for kw in sheet_keywords:
    count, used, skipped, seen = check_one_sheet_fast(kw)
    total_all += count
    elapsed_all += used or 0
    skip_total += skipped
    contracts_seen_all_sheets.update(seen)

st.success(f"ğŸ¯ å…¨éƒ¨æ£€æŸ¥å®Œæˆï¼Œå…± {total_all} å¤„é”™è¯¯ï¼Œæ€»è€—æ—¶ {elapsed_all:.2f} ç§’ã€‚")
st.info(f"è·³è¿‡å­—æ®µè¡¨ä¸­ç©ºåŸå¸‚ç»ç†åˆåŒæ•°é‡ï¼š{skip_total}")

# =====================================
# ğŸ•µï¸ æ¼å¡«æ£€æŸ¥
# =====================================
field_contracts = zd_df[contract_col_zd].dropna().astype(str).str.strip()
col_car_manager = find_col(zd_df, "æ˜¯å¦è½¦ç®¡å®¶", exact=True)
col_bonus_type = find_col(zd_df, "ææˆç±»å‹", exact=True)

missing_mask = ~field_contracts.isin(contracts_seen_all_sheets)
if col_car_manager:
    missing_mask &= ~(zd_df[col_car_manager].astype(str).str.strip().str.lower() == "æ˜¯")
if col_bonus_type:
    missing_mask &= ~zd_df[col_bonus_type].astype(str).str.strip().isin(["è”åˆç§Ÿèµ", "é©»åº—"])

zd_df_missing = zd_df.copy()
zd_df_missing["æ¼å¡«æ£€æŸ¥"] = ""
zd_df_missing.loc[missing_mask, "æ¼å¡«æ£€æŸ¥"] = "â— æ¼å¡«"
æ¼å¡«åˆåŒæ•° = zd_df_missing["æ¼å¡«æ£€æŸ¥"].eq("â— æ¼å¡«").sum()
st.warning(f"âš ï¸ å…±å‘ç° {æ¼å¡«åˆåŒæ•°} ä¸ªåˆåŒåœ¨è®°å½•è¡¨ä¸­æœªå‡ºç°ï¼ˆå·²æ’é™¤è½¦ç®¡å®¶ã€è”åˆç§Ÿèµã€é©»åº—ï¼‰")

# å¯¼å‡ºå­—æ®µè¡¨ï¼ˆå«æ¼å¡«æ ‡æ³¨ï¼‰
yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
wb_all = Workbook()
ws_all = wb_all.active
for c_idx, c in enumerate(zd_df_missing.columns, 1): ws_all.cell(1, c_idx, c)
for r_idx, row in enumerate(zd_df_missing.itertuples(index=False), 2):
    for c_idx, v in enumerate(row, 1):
        ws_all.cell(r_idx, c_idx, v)
        if zd_df_missing.columns[c_idx-1] == "æ¼å¡«æ£€æŸ¥" and v == "â— æ¼å¡«":
            ws_all.cell(r_idx, c_idx).fill = yellow_fill
out_all = BytesIO()
wb_all.save(out_all)
out_all.seek(0)
st.download_button("ğŸ“¥ ä¸‹è½½å­—æ®µè¡¨æ¼å¡«æ ‡æ³¨ç‰ˆ", out_all, "å­—æ®µè¡¨_æ¼å¡«æ ‡æ³¨ç‰ˆ.xlsx")

# ä»…æ¼å¡«
zd_df_only_missing = zd_df_missing[zd_df_missing["æ¼å¡«æ£€æŸ¥"] == "â— æ¼å¡«"].copy()
if not zd_df_only_missing.empty:
    wb2 = Workbook()
    ws2 = wb2.active
    for c_idx, c in enumerate(zd_df_only_missing.columns, 1): ws2.cell(1, c_idx, c)
    for r_idx, row in enumerate(zd_df_only_missing.itertuples(index=False), 2):
        for c_idx, v in enumerate(row, 1):
            ws2.cell(r_idx, c_idx, v)
            if zd_df_only_missing.columns[c_idx-1] == "æ¼å¡«æ£€æŸ¥" and v == "â— æ¼å¡«":
                ws2.cell(r_idx, c_idx).fill = yellow_fill
    out2 = BytesIO()
    wb2.save(out2)
    out2.seek(0)
    st.download_button("ğŸ“¥ ä¸‹è½½ä»…æ¼å¡«å­—æ®µè¡¨", out2, "å­—æ®µè¡¨_ä»…æ¼å¡«.xlsx")

st.success("âœ… æ‰€æœ‰æ£€æŸ¥ã€æ ‡æ³¨ä¸å¯¼å‡ºå®Œæˆï¼")

