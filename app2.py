# =====================================
# Streamlit Web App: åˆåŒè®°å½•è¡¨è‡ªåŠ¨å®¡æ ¸ï¼ˆå‘é‡åŒ– + å››Sheet + æ¼å¡«æ£€æŸ¥ + é©»åº—å®¢æˆ·ç‰ˆï¼‰
# =====================================

import streamlit as st
import pandas as pd
import time
from openpyxl import load_workbook, Workbook
from openpyxl.styles import PatternFill
from io import BytesIO

# =====================================
# ğŸ åº”ç”¨æ ‡é¢˜
# =====================================
st.title("ğŸ“Š æ¨¡æ‹Ÿå®é™…è¿ç”¨ç¯å¢ƒProjectï¼šäººäº‹ç”¨åˆåŒè®°å½•è¡¨è‡ªåŠ¨å®¡æ ¸ç³»ç»Ÿï¼ˆå‘é‡åŒ– + å››Sheet + æ¼å¡«æ£€æŸ¥ + é©»åº—å®¢æˆ·ç‰ˆï¼‰")

# =====================================
# ğŸ“‚ ä¸Šä¼ æ–‡ä»¶
# =====================================
uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼ ä»¥ä¸‹æ–‡ä»¶ï¼šè®°å½•è¡¨ã€æ”¾æ¬¾æ˜ç»†ã€å­—æ®µã€äºŒæ¬¡æ˜ç»†ã€é‡å¡æ•°æ®",
    type="xlsx",
    accept_multiple_files=True
)
if not uploaded_files or len(uploaded_files) < 5:
    st.warning("âš ï¸ è¯·ä¸Šä¼ æ‰€æœ‰ 5 ä¸ªæ–‡ä»¶åç»§ç»­")
    st.stop()
else:
    st.success("âœ… æ–‡ä»¶ä¸Šä¼ å®Œæˆ")

# =====================================
# ğŸ§° å·¥å…·å‡½æ•°
# =====================================
def find_file(files_list, keyword):
    for f in files_list:
        if keyword in f.name:
            return f
    raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ã€Œ{keyword}ã€çš„æ–‡ä»¶")

def normalize_colname(c):
    return str(c).strip().lower()

def find_col(df, keyword, exact=False):
    key = keyword.strip().lower()
    for col in df.columns:
        cname = normalize_colname(col)
        if (exact and cname == key) or (not exact and key in cname):
            return col
    return None

def find_sheet(xls, keyword):
    for s in xls.sheet_names:
        if keyword in s:
            return s
    raise ValueError(f"âŒ æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ã€Œ{keyword}ã€çš„sheet")

def normalize_num(val):
    if pd.isna(val): return None
    s = str(val).replace(",", "").strip()
    if s in ["", "-", "nan"]: return None
    try:
        if "%" in s: return float(s.replace("%", "")) / 100
        return float(s)
    except ValueError:
        return s

def same_date_ymd(a, b):
    try:
        da = pd.to_datetime(a, errors='coerce')
        db = pd.to_datetime(b, errors='coerce')
        if pd.isna(da) or pd.isna(db): return False
        return (da.year, da.month, da.day) == (db.year, db.month, db.day)
    except Exception:
        return False

def read_excel_clean(file, sheet_name=None, header=0):
    df = pd.read_excel(file, sheet_name=sheet_name, header=header)
    df.columns = [str(c).strip() for c in df.columns]
    return df

# =====================================
# ğŸ“– æ–‡ä»¶è¯»å–
# =====================================
main_file = find_file(uploaded_files, "è®°å½•è¡¨")
fk_file = find_file(uploaded_files, "æ”¾æ¬¾æ˜ç»†")
zd_file = find_file(uploaded_files, "å­—æ®µ")
ec_file = find_file(uploaded_files, "äºŒæ¬¡æ˜ç»†")
zk_file = find_file(uploaded_files, "é‡å¡æ•°æ®")

xls_main = pd.ExcelFile(main_file)
sheet_keywords = ["äºŒæ¬¡", "éƒ¨åˆ†æ‹…ä¿", "éšå·", "é©»åº—å®¢æˆ·"]

fk_df = read_excel_clean(fk_file, sheet_name=find_sheet(pd.ExcelFile(fk_file), "æœ¬å¸"))
zd_df = read_excel_clean(zd_file, sheet_name=find_sheet(pd.ExcelFile(zd_file), "é‡å¡"))
ec_df = read_excel_clean(ec_file)
zk_df = read_excel_clean(zk_file)

# =====================================
# ğŸ“Œ åˆåŒåˆ—
# =====================================
contract_col_fk = find_col(fk_df, "åˆåŒ", exact=True)
contract_col_zd = find_col(zd_df, "åˆåŒ", exact=True)
contract_col_ec = find_col(ec_df, "åˆåŒ", exact=True)
contract_col_zk = find_col(zk_df, "åˆåŒ", exact=True)

# =====================================
# ğŸ”— å­—æ®µæ˜ å°„
# =====================================
mapping_fk = {"æˆä¿¡æ–¹":"æˆä¿¡", "ç§Ÿèµæœ¬é‡‘":"æœ¬é‡‘", "ç§ŸèµæœŸé™æœˆ":"ç§ŸèµæœŸé™æœˆ",
              "å®¢æˆ·ç»ç†":"å®¢æˆ·ç»ç†", "èµ·ç§Ÿæ”¶ç›Šç‡":"æ”¶ç›Šç‡", "ä¸»è½¦å°æ•°":"ä¸»è½¦å°æ•°", "æŒ‚è½¦å°æ•°":"æŒ‚è½¦å°æ•°"}
mapping_zd = {"ä¿è¯é‡‘æ¯”ä¾‹":"ä¿è¯é‡‘æ¯”ä¾‹_2", "é¡¹ç›®ææŠ¥äºº":"ææŠ¥", "èµ·ç§Ÿæ—¶é—´":"èµ·ç§Ÿæ—¥_å•†",
              "ç§ŸèµæœŸé™æœˆ":"æ€»æœŸæ•°_å•†_èµ„äº§", "èµ·ç§Ÿæ”¶ç›Šç‡":"XIRR_å•†_èµ·ç§Ÿ", "æ‰€å±çœåŒº":"åŒºåŸŸ", "åŸå¸‚ç»ç†":"åŸå¸‚ç»ç†"}
mapping_ec = {"äºŒæ¬¡æ—¶é—´":"å‡ºæœ¬æµç¨‹æ—¶é—´"}
mapping_zk = {"æˆä¿¡æ–¹":"æˆä¿¡æ–¹"}

# =====================================
# âš¡ å‘é‡åŒ–æ¯”å¯¹å‡½æ•°ï¼ˆæ”¯æŒ exact å®¢æˆ·ç»ç†/åŸå¸‚ç»ç† + æ—¥æœŸ + ä¿è¯é‡‘æ¯”ä¾‹å®¹å·®ï¼‰
# =====================================
def compare_fields_vectorized(main_df, ref_df, main_contract_col, ref_contract_col, mapping_dict, tolerance_dict=None):
    tolerance_dict = tolerance_dict or {}
    main_df_clean = main_df.copy()
    main_df_clean[main_contract_col] = main_df_clean[main_contract_col].astype(str).str.strip()
    ref_df_clean = ref_df.copy()
    ref_df_clean[ref_contract_col] = ref_df_clean[ref_contract_col].astype(str).str.strip()

    ref_cols_needed = [ref_contract_col] + list(mapping_dict.values())
    missing_cols = [c for c in ref_cols_needed if c not in ref_df_clean.columns]
    if missing_cols:
        st.error(f"âŒ å‚è€ƒè¡¨ç¼ºå°‘åˆ—: {missing_cols}")
        mask_empty = pd.DataFrame(False, index=main_df.index, columns=mapping_dict.keys())
        return main_df_clean.copy(), mask_empty

    ref_sub = ref_df_clean[ref_cols_needed]
    merged = main_df_clean.merge(ref_sub, how="left", left_on=main_contract_col, right_on=ref_contract_col, suffixes=("", "_ref"))
    mask = pd.DataFrame(False, index=merged.index, columns=mapping_dict.keys())

    for main_col, ref_col in mapping_dict.items():
        if main_col not in merged.columns: continue
        main_vals = merged[main_col]
        ref_vals = merged[f"{ref_col}_ref"]
        is_date_col = any(k in main_col for k in ["æ—¥æœŸ","æ—¶é—´"]) or any(k in ref_col for k in ["æ—¥æœŸ","æ—¶é—´"])
        tol = tolerance_dict.get(main_col, 0)
        exact_match = main_col in ["å®¢æˆ·ç»ç†","åŸå¸‚ç»ç†"]

        # å‘é‡åŒ–æ¯”è¾ƒ
        if is_date_col:
            main_dt = pd.to_datetime(main_vals, errors='coerce').dt.normalize()
            ref_dt = pd.to_datetime(ref_vals, errors='coerce').dt.normalize()
            mask[main_col] = ~(main_dt.eq(ref_dt))
        else:
            main_num = main_vals.apply(normalize_num)
            ref_num = ref_vals.apply(normalize_num)
            num_mask = (main_num.notna() & ref_num.notna()) & ((main_num - ref_num).abs() > tol)
            text_mask = (~main_num.eq(ref_num)) & (~num_mask)
            if exact_match:
                text_mask = ~main_vals.astype(str).str.strip().eq(ref_vals.astype(str).str.strip())
            nan_mask = (main_num.isna() & ref_num.notna()) | (main_num.notna() & ref_num.isna())
            mask[main_col] = num_mask | text_mask | nan_mask

    return merged, mask

# =====================================
# ğŸ§® å• sheet æ£€æŸ¥
# =====================================
def check_one_sheet(sheet_keyword):
    start_time = time.time()
    main_df = read_excel_clean(main_file, sheet_name=find_sheet(xls_main, sheet_keyword), header=1)
    output_path = f"è®°å½•è¡¨_{sheet_keyword}_å®¡æ ¸æ ‡æ³¨ç‰ˆ.xlsx"
    empty_row = pd.DataFrame([[""]*len(main_df.columns)], columns=main_df.columns)
    pd.concat([empty_row, main_df], ignore_index=True).to_excel(output_path, index=False)
    wb = load_workbook(output_path)
    ws = wb.active
    red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

    global contract_col_main
    contract_col_main = find_col(main_df, "åˆåŒ", exact=True)
    if not contract_col_main:
        st.error(f"âŒ åœ¨ã€Œ{sheet_keyword}ã€ä¸­æœªæ‰¾åˆ°åˆåŒåˆ—ã€‚")
        return 0, None, 0, set()

    total_errors = 0
    contracts_seen = set()
    progress = st.progress(0)
    status = st.empty()

    merged_fk, mask_fk = compare_fields_vectorized(main_df, fk_df, contract_col_main, contract_col_fk, mapping_fk)
    merged_zd, mask_zd = compare_fields_vectorized(main_df, zd_df, contract_col_main, contract_col_zd, mapping_zd, tolerance_dict={"ä¿è¯é‡‘æ¯”ä¾‹":0.005})
    merged_ec, mask_ec = compare_fields_vectorized(main_df, ec_df, contract_col_main, contract_col_ec, mapping_ec)
    merged_zk, mask_zk = compare_fields_vectorized(main_df, zk_df, contract_col_main, contract_col_zk, mapping_zk)

    mask_all = pd.concat([mask_fk, mask_zd, mask_ec, mask_zk], axis=1)
    mask_any = mask_all.any(axis=1)

    for r_idx, row in main_df.iterrows():
        contracts_seen.add(str(row[contract_col_main]).strip())
        for col in mask_all.columns:
            if mask_all.at[r_idx,col]:
                c_idx = list(main_df.columns).index(col)+1
                ws.cell(r_idx+3,c_idx).fill = red_fill
        if mask_any.at[r_idx]:
            c_contract = list(main_df.columns).index(contract_col_main)+1
            ws.cell(r_idx+3,c_contract).fill = yellow_fill
        if (r_idx+1) % 10 == 0:
            status.text(f"æ£€æŸ¥ã€Œ{sheet_keyword}ã€... {r_idx+1}/{len(main_df)}")
        progress.progress((r_idx+1)/len(main_df))

    output = BytesIO()
    wb.save(output)
    output.seek(0)
    st.download_button(f"ğŸ“¥ ä¸‹è½½ {sheet_keyword} å®¡æ ¸æ ‡æ³¨ç‰ˆ", output, f"è®°å½•è¡¨_{sheet_keyword}_å®¡æ ¸æ ‡æ³¨ç‰ˆ.xlsx")
    total_errors = mask_any.sum()
    elapsed = time.time()-start_time
    st.success(f"âœ… {sheet_keyword} æ£€æŸ¥å®Œæˆï¼Œå…± {total_errors} å¤„é”™è¯¯ï¼Œç”¨æ—¶ {elapsed:.2f} ç§’ã€‚")
    return total_errors, elapsed, 0, contracts_seen

# =====================================
# ğŸ§¾ å¤š sheet å¾ªç¯
# =====================================
total_all = elapsed_all = skip_total = 0
contracts_seen_all_sheets = set()
for kw in sheet_keywords:
    count, used, skipped, seen = check_one_sheet(kw)
    total_all += count
    elapsed_all += used or 0
    skip_total += skipped
    contracts_seen_all_sheets.update(seen)
st.success(f"ğŸ¯ å…¨éƒ¨å®¡æ ¸å®Œæˆï¼Œå…± {total_all} å¤„é”™è¯¯ï¼Œæ€»è€—æ—¶ {elapsed_all:.2f} ç§’ã€‚")

# =====================================
# ğŸ•µï¸ æ¼å¡«æ£€æŸ¥
# =====================================
field_contracts = zd_df[contract_col_zd].dropna().astype(str).str.strip()
col_car_manager = find_col(zd_df, "æ˜¯å¦è½¦ç®¡å®¶", exact=True)
col_bonus_type = find_col(zd_df, "ææˆç±»å‹", exact=True)
missing_contracts_mask = (~field_contracts.isin(contracts_seen_all_sheets))
if col_car_manager:
    missing_contracts_mask &= ~(zd_df[col_car_manager].astype(str).str.strip().str.lower() == "æ˜¯")
if col_bonus_type:
    missing_contracts_mask &= ~(zd_df[col_bonus_type].astype(str).str.strip().isin(["è”åˆç§Ÿèµ","é©»åº—"]))

zd_df_missing = zd_df.copy()
zd_df_missing["æ¼å¡«æ£€æŸ¥"] = ""
zd_df_missing.loc[missing_contracts_mask, "æ¼å¡«æ£€æŸ¥"] = "â— æ¼å¡«"
æ¼å¡«åˆåŒæ•° = zd_df_missing["æ¼å¡«æ£€æŸ¥"].eq("â— æ¼å¡«").sum()
st.warning(f"âš ï¸ å…±å‘ç° {æ¼å¡«åˆåŒæ•°} ä¸ªåˆåŒåœ¨è®°å½•è¡¨ä¸­æœªå‡ºç°ï¼ˆå·²æ’é™¤è½¦ç®¡å®¶ã€è”åˆç§Ÿèµã€é©»åº—ï¼‰")

# =====================================
# ğŸ“¤ å¯¼å‡ºå­—æ®µè¡¨
# =====================================
yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
wb_all = Workbook()
ws_all = wb_all.active
for c_idx, c in enumerate(zd_df_missing.columns,1): ws_all.cell(1,c_idx,c)
for r_idx, row in enumerate(zd_df_missing.itertuples(index=False),2):
    for c_idx, v in enumerate(row,1):
        ws_all.cell(r_idx,c_idx,v)
        if zd_df_missing.columns[c_idx-1]=="æ¼å¡«æ£€æŸ¥" and v=="â— æ¼å¡«":
            ws_all.cell(r_idx,c_idx).fill = yellow_fill
output_all = BytesIO()
wb_all.save(output_all)
output_all.seek(0)
st.download_button("ğŸ“¥ ä¸‹è½½å­—æ®µè¡¨æ¼å¡«æ ‡æ³¨ç‰ˆ", output_all,"å­—æ®µè¡¨_æ¼å¡«æ ‡æ³¨ç‰ˆ.xlsx")

zd_df_only_missing = zd_df_missing[zd_df_missing["æ¼å¡«æ£€æŸ¥"]=="â— æ¼å¡«"].copy()
if not zd_df_only_missing.empty:
    wb2 = Workbook()
    ws2 = wb2.active
    for c_idx, c in enumerate(zd_df_only_missing.columns,1): ws2.cell(1,c_idx,c)
    for r_idx,row in enumerate(zd_df_only_missing.itertuples(index=False),2):
        for c_idx,v in enumerate(row,1):
            ws2.cell(r_idx,c_idx,v)
            if zd_df_only_missing.columns[c_idx-1]=="æ¼å¡«æ£€æŸ¥" and v=="â— æ¼å¡«":
                ws2.cell(r_idx,c_idx).fill = yellow_fill
    out2 = BytesIO()
    wb2.save(out2)
    out2.seek(0)
    st.download_button("ğŸ“¥ ä¸‹è½½ä»…æ¼å¡«å­—æ®µè¡¨", out2,"å­—æ®µè¡¨_ä»…æ¼å¡«.xlsx")

st.success("âœ… æ‰€æœ‰æ£€æŸ¥ã€æ ‡æ³¨ä¸å¯¼å‡ºå®Œæˆï¼")
